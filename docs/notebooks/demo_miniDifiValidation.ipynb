{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e085ec8-2861-4597-ab66-d49b9337c207",
   "metadata": {},
   "source": [
    "## Mini-difi vs. brute-force linking tests\n",
    "\n",
    "This demonstration takes the output from midway through a Sorcha run with the demoset of 100k TNOs before linking is applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "878bd071-d694-4bdf-91d2-16e29e090df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from astropy.coordinates import SkyCoord\n",
    "import astropy.units as u"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175c0242-33c3-4461-9fd5-2690d315b7e9",
   "metadata": {},
   "source": [
    "### Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b9fbebd-3038-4645-bc5a-d9b58b113a7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of objects: 994\n",
      "Number of observations: 62354\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"midSorcha_TNOs.csv\").drop(columns=[\"Unnamed: 0\"]).reset_index()\n",
    "print(f\"Number of objects: {len(df['ssObjectId'].unique())}\")\n",
    "print(f\"Number of observations: {len(df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094f4821-86ca-4446-a1f4-8e8d5a16d240",
   "metadata": {},
   "source": [
    "### The \"brute force\" miniDifi implementation.\n",
    "\n",
    "This should be a (hopefully) more pedagogically easier to follow implementation of the mock linker algorithm.\n",
    "\n",
    "The results should match the fast (but harder to follow) implementation in Sorcha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5df799e8-2f9b-433a-b4a8-1751fc481186",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Compute if the current night has observations that will qualify as traclkets\n",
    "#\n",
    "\n",
    "def compute_nights(df, night_start_utc_days = 17.0 / 24.0):\n",
    "    # this computes the integer night (== the MJD of the evening the observations started)\n",
    "    # for the observations in df.\n",
    "\n",
    "    tshifted = df[\"midPointTai\"] - night_start_utc_days\n",
    "    return tshifted.astype(int)\n",
    "\n",
    "def has_tracklet(df, minlen_arcsec=1, maxdt_minutes=90):\n",
    "    # this computes whether a given night has /any/ observations close enough to be\n",
    "    # made into a tracklet.\n",
    "    #\n",
    "    # WARNING: the input dataframe must be for _a single_ object.\n",
    "\n",
    "    if \"ssObjectId\" in df.columns:\n",
    "        assert len(df[\"ssObjectId\"].unique()) == 1, \"This function must be run on a single object\"\n",
    "\n",
    "    maxdt = maxdt_minutes / 60. / 24.\n",
    "    minlen = minlen_arcsec / 3600.\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        for j in range(i+1, len(df)):\n",
    "            t0, t1 = df[\"midPointTai\"].iloc[i], df[\"midPointTai\"].iloc[j]\n",
    "            ra0, ra1 = df[\"ra\"].iloc[i], df[\"ra\"].iloc[j]\n",
    "            dec0, dec1 = df[\"decl\"].iloc[i], df[\"decl\"].iloc[j]\n",
    "\n",
    "            # is this pair too spread out in time?\n",
    "            dt = t1 - t0\n",
    "            assert dt > 0, (dt, t1, t0)\n",
    "            if dt > maxdt:\n",
    "                continue\n",
    "\n",
    "            coord1 = SkyCoord(ra=ra0*u.degree, dec=dec0*u.degree, frame='icrs')\n",
    "            coord2 = SkyCoord(ra=ra1*u.degree, dec=dec1*u.degree, frame='icrs')\n",
    "            angular_distance = coord1.separation(coord2)\n",
    "            dist = angular_distance.deg\n",
    "\n",
    "            # is this pair too close in distance?\n",
    "            if dist < minlen:\n",
    "                continue\n",
    "\n",
    "            # this combo will make a tracklet; return true!\n",
    "            ##print(f'dt = {dt*24*60:.2f} min, sep = {dist*3600:.2f}\"')\n",
    "            return True\n",
    "    \n",
    "    return False\n",
    "\n",
    "def nights_with_tracklets(df):\n",
    "    # returns a list (as ndarray) of nights (MJD) with tracklets\n",
    "\n",
    "    if \"ssObjectId\" in df.columns:\n",
    "        assert len(df[\"ssObjectId\"].unique()) == 1, \"This function must be run on a single object\"\n",
    "\n",
    "    # Filter the DataFrame to only keep rows where the 'night' value appears 2 or more times\n",
    "    df_filtered = df[df.groupby('night')['night'].transform('count') >= 2].reset_index()\n",
    "\n",
    "    # Now, for each night compute if it has a tracklet by calling has_tracklet()\n",
    "    nightHasTracklet = df_filtered.groupby(\"night\").apply(has_tracklet, include_groups=False)\n",
    "    nightsWithTracklets = nightHasTracklet[nightHasTracklet]\n",
    "\n",
    "    return nightsWithTracklets.index.values\n",
    "\n",
    "def enumerateOpportunities(nights, window=14, nlink=3):\n",
    "    #\n",
    "    # Enumerate all discovery opportunities given the list of nights with tracklets.\n",
    "    #\n",
    "    # Note: window is inclusive of the most recent night, and exclusive of the -window night.\n",
    "    #\n",
    "    # For example, if window=2, that means we'd search for tracklets tonight and yesteday,\n",
    "    # but not day before yesterday. I.e., if tonight is the MJD of current night, the condition\n",
    "    # to include a night into the tracklet suite is:\n",
    "    #\n",
    "    #     tonight - window < tracklet_night  and  tracklet_night <= tonight\n",
    "    #\n",
    "    # (i.e., it's \\lt on the first comparison, not \\le).\n",
    "    \n",
    "    # we'll be collecting unique opportunities here\n",
    "    opportunities = set()\n",
    "    if len(nights) == 0:\n",
    "        return opportunities\n",
    "\n",
    "    # go from the first to last night, and for each find the\n",
    "    # tracklets in the trailing window\n",
    "    for t1 in range(nights.min(), nights.max()+window+1):\n",
    "        t0 = t1 - window # trailing window\n",
    "        tracklets = tuple(nights[(t0 < nights) & (nights <= t1)])\n",
    "\n",
    "        # not enough tracklets to link? continue...\n",
    "        if len(tracklets) < nlink:\n",
    "            continue\n",
    "\n",
    "        opportunities.add(tracklets)\n",
    "\n",
    "    return opportunities\n",
    "\n",
    "def linkObject(df):\n",
    "    #\n",
    "    # find and return the list of all discovery opportunities for a given\n",
    "    # object.\n",
    "    #\n",
    "    # WARNING: the df must be for a single object (!!).\n",
    "    #\n",
    "\n",
    "    nightsWithTracklets = nights_with_tracklets(df)\n",
    "    opps = enumerateOpportunities(nightsWithTracklets)\n",
    "    return opps\n",
    "\n",
    "def linkObservations(df):\n",
    "    #\n",
    "    # The main driver. Given a list of observations of multiple objects,\n",
    "    # analyze whether each object can be linked and return the number of\n",
    "    # linking opportunities.\n",
    "    #\n",
    "\n",
    "    df[\"night\"] = compute_nights(df)\n",
    "\n",
    "    res = df.groupby(\"ssObjectId\").apply(\n",
    "        lambda df: len(linkObject(df)),\n",
    "        include_groups=False)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e3fe5f-8e6d-4ca5-824b-9f951ec2f2b2",
   "metadata": {},
   "source": [
    "### Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17fdfbb2-26f3-48c1-a725-4bae870d5cc7",
   "metadata": {},
   "source": [
    "Run the brute-force linker. It returns a series with the number of discovery opportunities for each object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0060849-6435-45cc-834b-c3a5baae451f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20.1 s, sys: 48.9 ms, total: 20.2 s\n",
      "Wall time: 20.3 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ssObjectId\n",
       "STC001TFa     9\n",
       "STC001TGa     2\n",
       "STC001THa    17\n",
       "STC001TIa     2\n",
       "STC001TJa     2\n",
       "             ..\n",
       "STC0029va     4\n",
       "STC0029wa     7\n",
       "STC0029xa     1\n",
       "STC0029ya    14\n",
       "STC0029za    14\n",
       "Length: 994, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "bf = linkObservations(df)\n",
    "bf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80261f1d-13bb-4d57-9873-8027620252a5",
   "metadata": {},
   "source": [
    "Now run the Sorcha miniDifi implementation.\n",
    "\n",
    "Note: if you're paying attention to runtime, run this cell at least twice as the first time you're running there will be lots of overhead with module loading and JIT compilation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5d6264b-ff94-4517-a325-ef0a7daa731a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.81 s, sys: 358 ms, total: 5.16 s\n",
      "Wall time: 10.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import sorcha.modules.PPMiniDifi as md\n",
    "\n",
    "df_all = pd.read_csv(\"midSorcha_TNOs.csv\").drop(columns=[\"Unnamed: 0\"]).reset_index()\n",
    "\n",
    "# Convert to ndarray\n",
    "nameLen = df_all[\"ssObjectId\"].str.len().max()\n",
    "obsv = np.asarray(\n",
    "        df_all.to_records(\n",
    "            index=False,\n",
    "            column_dtypes=dict(_name=f\"a{nameLen}\", diaSourceId=\"u8\", midPointTai=\"f8\", ra=\"f8\", decl=\"f8\"),\n",
    "        )\n",
    "    )\n",
    "\n",
    "# run minidifi\n",
    "minidifi = md.linkObservations(obsv, seed=42, p=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2d8c84-1312-4646-a403-edea9c6b7d19",
   "metadata": {},
   "source": [
    "### Comparison\n",
    "\n",
    "If the two implementations match, there should be no assertions and an the dataframe of differences will be empty in the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cdc27b2f-c5d0-4d0f-b2ca-22a461e42afb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of objects: 994\n",
      "Total number of equal objects: 994\n",
      "Differences between miniDifi and brute force (note: empty is good!):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bf_discoveryChances</th>\n",
       "      <th>discoveryChances</th>\n",
       "      <th>equal</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ssObjectId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [bf_discoveryChances, discoveryChances, equal]\n",
       "Index: []"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bf_res = pd.DataFrame({\"bf_discoveryChances\": bf})\n",
    "md_res = pd.DataFrame(minidifi).set_index(\"ssObjectId\")[[\"discoveryChances\"]]\n",
    "\n",
    "# assert all objects are there in both dataframes\n",
    "assert np.all(bf_res.index.values == md_res.index.values)\n",
    "print(f\"Total number of objects: {len(bf_res)}\")\n",
    "\n",
    "# join the two dataframes\n",
    "res = bf_res.join(md_res)\n",
    "res[\"equal\"] = res[\"bf_discoveryChances\"] == res[\"discoveryChances\"]\n",
    "print(f\"Total number of equal objects: {np.count_nonzero(res['equal'])}\")\n",
    "\n",
    "# find where they differ\n",
    "print(\"Differences between miniDifi and brute force (note: empty is good!):\")\n",
    "res[~res[\"equal\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f785000",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
