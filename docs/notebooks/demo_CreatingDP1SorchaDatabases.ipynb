{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be993b8f-462a-4752-9052-35f26f3d6f27",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-09T15:08:46.726719Z",
     "iopub.status.busy": "2025-07-09T15:08:46.726194Z",
     "iopub.status.idle": "2025-07-09T15:08:46.729396Z",
     "shell.execute_reply": "2025-07-09T15:08:46.728844Z",
     "shell.execute_reply.started": "2025-07-09T15:08:46.726693Z"
    }
   },
   "source": [
    "## Creating the SQLite Databases Necessary for DP1 Sorcha\n",
    "\n",
    "This notebook creates the SQLite databases needed to run **DP1** in Sorcha. This code has been created to run in the Rubin Science Platform notebooks to obtain the databases. It creates two files and outputs the queries needed for the Sorcha config file:\n",
    "\n",
    "1. **Visits database** from `CcdVisit`\n",
    "2. **Pointing database** from `Visit`\n",
    "\n",
    "---\n",
    "For running DP1, obtain the databases using this notebook, run the command line arg `sorcha init` and select the **DP1 config file** option. Then run the code with:\n",
    "\n",
    "sorcha run -c DP1_visits_footprint.ini --pd dp1_pointing.db --ob orbits_filename.csv -p colours_filename.csv -o ./ -s dp1 --vd dp1_ccdvisits.db \n",
    "\n",
    "orbits_filename.csv and colours_filename.csv should be your input files for object's orbits and colours, respectively.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bea7839d-c4c2-4127-a79c-109a59b587d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-18T13:25:36.668095Z",
     "iopub.status.busy": "2025-07-18T13:25:36.667879Z",
     "iopub.status.idle": "2025-07-18T13:25:39.293497Z",
     "shell.execute_reply": "2025-07-18T13:25:39.292812Z",
     "shell.execute_reply.started": "2025-07-18T13:25:36.668076Z"
    }
   },
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "from lsst.rsp import get_tap_service\n",
    "from lsst.daf.butler import Butler\n",
    "from rubin_sim.phot_utils import fwhm_geom2_fwhm_eff\n",
    "import numpy as np\n",
    "\n",
    "def create_visits_database(query, sqlite_db_file= \"dp1_ccdvisits.db\", table_name='observations',service = get_tap_service(\"tap\"), butler = Butler('dp1', collections=\"LSSTComCam/DP1\")):\n",
    "    \"\"\"\n",
    "    Create a SQLite ccd visits database.\n",
    "    \"\"\"\n",
    "\n",
    "    job = service.submit_job(query)\n",
    "    job.run()\n",
    "    job.wait(phases=['COMPLETED', 'ERROR'])\n",
    "    print('Job phase is', job.phase)\n",
    "    if job.phase == 'ERROR':\n",
    "        job.raise_if_error()\n",
    "    df = job.fetch_result().to_table().to_pandas()\n",
    "    job.delete()\n",
    "\n",
    "    conn = sqlite3.connect(sqlite_db_file)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    cursor.execute(f\"DROP TABLE IF EXISTS {table_name}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    cursor.execute(f'''\n",
    "    CREATE TABLE {table_name} (\n",
    "        visitId INTEGER,\n",
    "        ccdVisitId INTEGER,\n",
    "        dec REAL,\n",
    "        ra REAL,\n",
    "        llcdec REAL,\n",
    "        llcra REAL,\n",
    "        lrcdec REAL,\n",
    "        lrcra REAL,\n",
    "        ulcdec REAL,\n",
    "        ulcra REAL,\n",
    "        urcdec REAL,\n",
    "        urcra REAL,\n",
    "        magLim REAL\n",
    "    )\n",
    "    ''')\n",
    "\n",
    "    df.to_sql(table_name, conn, if_exists='replace', index=False)\n",
    "    \n",
    "    conn.commit()\n",
    "    \n",
    "    try:\n",
    "    \n",
    "        cursor.execute(\n",
    "            \"CREATE INDEX idx_obs ON observations(visitId, ccdVisitId, llcra, llcdec, lrcra, lrcdec, urcra, urcdec, ulcra, ulcdec, magLim)\"\n",
    "        )\n",
    "        \n",
    "        conn.commit()\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating index: {e}\")\n",
    "\n",
    "    \n",
    "    conn.close()\n",
    "    \n",
    "    print(f\"Visits database created at '{sqlite_db_file}' with table '{table_name}'.\\n\")\n",
    "    fov_query = f'SELECT llcra, llcdec, lrcra, lrcdec, urcra, urcdec, ulcra, ulcdec, ra as ra_centre, dec as dec_centre, ccdVisitId as detectorID, magLim as limMag_perChip  FROM {table_name} WHERE visitId = ?'\n",
    "    print(\"sorcha FOV config variable visits_query will be\\n\")\n",
    "    print(\"    \\033[1;32m\" + fov_query + \"\\033[0m\\n\")\n",
    "\n",
    "\n",
    "def create_pointing_database(query, seeing_query, sqlite_db_file= \"dp1_pointing.db\", table_name='observations',service = get_tap_service(\"tap\"), butler = Butler('dp1', collections=\"LSSTComCam/DP1\")):\n",
    "    \"\"\"\n",
    "    Create a SQLite pointing database.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    query : str\n",
    "        query for visits DP1 database.\n",
    "\n",
    "    sqlite_db_file : str, optional\n",
    "        Path to the SQLite database file to create or overwrite.\n",
    "\n",
    "    table_name : str, optional\n",
    "        Name of the table to create in the SQLite database. Default is 'observations'.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "\n",
    "    job = service.submit_job(query)\n",
    "    job.run()\n",
    "    job.wait(phases=['COMPLETED', 'ERROR'])\n",
    "    print('Job phase is', job.phase)\n",
    "    if job.phase == 'ERROR':\n",
    "        job.raise_if_error()\n",
    "    df = job.fetch_result().to_table().to_pandas()\n",
    "    job.delete()\n",
    "\n",
    "    conn = sqlite3.connect(sqlite_db_file)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    cursor.execute(f\"DROP TABLE IF EXISTS {table_name}\")\n",
    "\n",
    "    \n",
    "\n",
    "    job = service.submit_job(seeing_query)\n",
    "    job.run()\n",
    "    job.wait(phases=['COMPLETED', 'ERROR'])\n",
    "    print('Job phase is', job.phase)\n",
    "    if job.phase == 'ERROR':\n",
    "        job.raise_if_error()\n",
    "    df_see = job.fetch_result().to_table().to_pandas()\n",
    "    job.delete()\n",
    "    seeing_list = []\n",
    "    magLim_list = []\n",
    "    for visitId in df[\"visit\"]:\n",
    "\n",
    "        seeing_per_id = df_see.loc[df_see[\"visitId\"] == visitId, \"seeing\"]\n",
    "        magLim_per_id = df_see.loc[df_see[\"visitId\"] == visitId, \"magLim\"]\n",
    "        \n",
    "        seeing = np.mean(seeing_per_id) if not seeing_per_id.empty else np.nan\n",
    "        magLim = np.mean(magLim_per_id) if not magLim_per_id.empty else np.nan\n",
    "        \n",
    "        seeing_list.append(seeing)\n",
    "        magLim_list.append(magLim)\n",
    "\n",
    "    df[\"magLim\"] = magLim_list\n",
    "    df[\"seeing\"] = seeing_list\n",
    "\n",
    "    df[\"effseeing\"] = fwhm_geom2_fwhm_eff(df[\"seeing\"])\n",
    "    cursor.execute(f'''\n",
    "    CREATE TABLE {table_name} (\n",
    "        band TEXT,\n",
    "        expTime INTEGER,\n",
    "        dec REAL,\n",
    "        ra REAL,\n",
    "        obsStart REAL,\n",
    "        skyRotation REAL,\n",
    "        visit INTEGER PRIMARY KEY,\n",
    "        expMidptMJD REAL,\n",
    "        seeing REAL,\n",
    "        effseeing REAL,\n",
    "        magLim Real\n",
    "    )\n",
    "    ''')\n",
    "\n",
    "    df.to_sql(table_name, conn, if_exists='replace', index=False)\n",
    "    \n",
    "    conn.commit()\n",
    "    \n",
    "    conn.close()\n",
    "    \n",
    "    print(f\"Pointing database created at '{sqlite_db_file}' with table '{table_name}'.\\n\")\n",
    "\n",
    "    \n",
    "    pointing_query = f'SELECT visit as observationId, expMidptMJD as observationMidpointMJD_TAI, obsStart as visitTime,expTime as visitExposureTime, band as filter,  ra as fieldRA_deg, dec as fieldDec_deg, skyRotation as fieldRotSkyPos_deg, seeing as seeingFwhmGeom_arcsec, effseeing as seeingFwhmEff_arcsec, magLim as fieldFiveSigmaDepth_mag FROM {table_name} order by observationId'\n",
    "    \n",
    "    print(\"sorcha inputs config variable pointing_sql_query will be\\n\")\n",
    "    print(\"    \\033[1;32m\" + pointing_query + \"\\033[0m\\n\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6cb3205c-264b-4583-bc84-c0fb13b12cf3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-18T13:25:39.296010Z",
     "iopub.status.busy": "2025-07-18T13:25:39.295797Z",
     "iopub.status.idle": "2025-07-18T13:26:00.604444Z",
     "shell.execute_reply": "2025-07-18T13:26:00.603803Z",
     "shell.execute_reply.started": "2025-07-18T13:25:39.295990Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job phase is COMPLETED\n",
      "Visits database created at 'dp1_ccdvisits.db' with table 'observations'.\n",
      "\n",
      "sorcha FOV config variable visits_query will be\n",
      "\n",
      "    \u001b[1;32mSELECT llcra, llcdec, lrcra, lrcdec, urcra, urcdec, ulcra, ulcdec, ra as ra_centre, dec as dec_centre, ccdVisitId as detectorID, magLim as limMag_perChip  FROM observations WHERE visitId = ?\u001b[0m\n",
      "\n",
      "Job phase is COMPLETED\n",
      "Job phase is COMPLETED\n",
      "Pointing database created at 'dp1_pointing.db' with table 'observations'.\n",
      "\n",
      "sorcha inputs config variable pointing_sql_query will be\n",
      "\n",
      "    \u001b[1;32mSELECT visit as observationId, expMidptMJD as observationMidpointMJD_TAI, obsStart as visitTime,expTime as visitExposureTime, band as filter,  ra as fieldRA_deg, dec as fieldDec_deg, skyRotation as fieldRotSkyPos_deg, seeing as seeingFwhmGeom_arcsec, effseeing as seeingFwhmEff_arcsec, magLim as fieldFiveSigmaDepth_mag FROM observations order by observationId\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "datarelease = \"dp1\"\n",
    "\n",
    "# creating service and butler to query database\n",
    "service = get_tap_service(\"tap\")\n",
    "butler = Butler(datarelease, collections=\"LSSTComCam/DP1\")\n",
    "\n",
    "\n",
    "\n",
    "# visits database query. This will create the ccdvisits.db and give the needed query for Sorcha\n",
    "visits_query = \"SELECT ccdVisitId,dec,llcdec,llcra,lrcdec,lrcra,magLim,ra, ulcdec,ulcra,urcdec,urcra,visitId FROM \"+datarelease+\".CcdVisit\"\n",
    "create_visits_database(visits_query, service = service, butler = butler)\n",
    "\n",
    "\n",
    "# Pointing database query. This will create the pointing.db and give the needed query for Sorcha\n",
    "pointing_query = \"SELECT band,dec,expTime,obsStart,ra,skyRotation,visit,expMidptMJD FROM \"+datarelease+\".Visit\"\n",
    "seeing_query = \"SELECT visitId, seeing, magLim FROM \"+datarelease+\".CcdVisit\" # used to get average seeing per observation from per ccd. \n",
    "create_pointing_database(pointing_query, seeing_query, service = service, butler = butler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92d5089-bc4e-4ae8-934c-edb91ac561e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LSST",
   "language": "python",
   "name": "lsst"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
